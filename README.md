# GAN para Fashion MNIST 

![Fashion MNIST GAN](https://github.com/warc0s/Fashion_MNIST_GAN/blob/main/logo.jpg?raw=true)

Este repositorio contiene dos implementaciones de una Red Generativa Antag贸nica (GAN) entrenada sobre el dataset **Fashion MNIST**. Se han desarrollado dos versiones utilizando **TensorFlow** y **PyTorch**, permitiendo comparar el rendimiento y tiempos de entrenamiento entre CPU y GPU.

---

## ndice

- [Introducci贸n](#introducci贸n)
- [Caracter铆sticas](#caracter铆sticas)
- [Arquitectura de la GAN](#arquitectura-de-la-gan)
- [Detalles del Entrenamiento](#detalles-del-entrenamiento)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [C贸mo Ejecutarlo](#c贸mo-ejecutarlo)
- [Resultados](#resultados)
- [Licencia](#licencia)

---

## Introducci贸n

En este proyecto se ha implementado una GAN con el objetivo de generar im谩genes similares a las del dataset Fashion MNIST. La GAN se compone de dos redes neuronales:  
- **Generador:** Encargado de crear im谩genes falsas a partir de un vector de ruido (espacio latente).  
- **Discriminador:** Su funci贸n es distinguir entre im谩genes reales y las generadas.

Se han creado dos versiones del entrenamiento:
- **TensorFlow**: Ejecutado en CPU (Ryzen 7 8700G).
- **PyTorch**: Ejecutado en GPU (NVIDIA T4 en Google Colab).

---

## Caracter铆sticas

- **Implementaci贸n Dual:** Tanto en TensorFlow como en PyTorch, permitiendo comparar diferencias en sintaxis y rendimiento.
- **Entrenamiento en Diferentes Hardwares:**  
  - **TensorFlow (CPU - Ryzen 7 8700G):**  
    - Tiempo por 茅poca: *4m 30s*  
    - Tiempo total (100 茅pocas): *7h 30m*
  - **PyTorch (GPU - T4 en Google Colab):**  
    - Tiempo por 茅poca: *26s*  
    - Tiempo total (100 茅pocas): *44m*
- **Resultados Comparables:** A pesar de las diferencias en hardware y tiempos de entrenamiento, el resultado final de ambas implementaciones es pr谩cticamente id茅ntico.
- **Modelos y Visualizaciones:** Se subir谩n 煤nicamente los modelos entrenados al **epoch 100** de ambas versiones. Adem谩s, se han guardado im谩genes generadas cada 5 茅pocas durante el entrenamiento.

---

## Arquitectura de la GAN

La arquitectura utilizada en ambas implementaciones (TensorFlow y PyTorch) es la siguiente:

### Generador
- **Entrada:** Un vector de ruido de dimensi贸n 100 (espacio latente).
- **Capas:**
  1. **Capa Densa + Normalizaci贸n:** Transforma el vector de entrada a un mapa de caracter铆sticas de dimensi贸n *7x7x256*.
  2. **Reshape:** Se reorganiza la salida en una forma de tensor 7x7x256.
  3. **Convoluciones Transpuestas:**  
     - **Primera capa:** Incrementa la dimensi贸n de 7x7 a 14x14 utilizando una convoluci贸n transpuesta, seguida de normalizaci贸n y activaci贸n *LeakyReLU*.
     - **Segunda capa:** Aumenta la dimensi贸n de 14x14 a 28x28, tambi茅n con normalizaci贸n y *LeakyReLU*.
  4. **Capa Final:** Genera una imagen de 28x28x1, usando la funci贸n de activaci贸n *tanh* para obtener valores en el rango [-1, 1].

### Discriminador
- **Entrada:** Im谩genes de tama帽o 28x28x1.
- **Capas:**
  1. **Convoluciones:** Se aplican dos capas convolucionales con *LeakyReLU* y *Dropout* para evitar sobreajuste.
  2. **Flatten:** Aplana el tensor para preparar la salida de la red.
  3. **Capa Densa Final:** Produce una salida 煤nica con activaci贸n *sigmoid*, que indica la probabilidad de que la imagen sea real.

> **Nota:** En PyTorch, la definici贸n y estructuraci贸n de estas capas es an谩loga, utilizando las correspondientes clases y m茅todos propios del framework.

---

## Detalles del Entrenamiento

- **Dataset:** Fashion MNIST, preprocesado para normalizar las im谩genes en el rango [-1, 1] y con el formato adecuado (28x28x1).
- **Optimizaci贸n:**  
  - **Funci贸n de P茅rdida:** Entrop铆a cruzada binaria.  
  - **Optimizadores:** Se utiliza Adam con tasa de aprendizaje de 1e-4 tanto para el generador como para el discriminador.
- **Batch Size:** 32.
- **pocas:** 100 en total.  
  - **Guardado de Modelos e Im谩genes:**  
    - Cada 5 茅pocas se guardan los modelos en formato `.keras` o `.pt` en Pytorch, y se generan im谩genes de ejemplo en una cuadr铆cula 3x3, que se guardan para seguimiento visual del entrenamiento.
- **Comparativa de Rendimiento:**  
  - *TensorFlow en CPU* es considerablemente m谩s lento que *PyTorch en GPU*, pero los resultados finales son comparables.

---

## Estructura del Repositorio

```plaintext
.
 models/                  # Modelos entrenados (solo epoch 100)
 img_train_epochs/        # Im谩genes generadas cada 5 茅pocas hasta el epoch 100
 mnist_gan_tensorflow.ipynb  # Notebook de TensorFlow
 mnist_gan_pytorch.ipynb       # Notebook de PyTorch
 README.md                # Este archivo
```

- **Notebooks:**  
  Los notebooks contienen el c贸digo completo para entrenar la GAN en cada framework, con comentarios sobre el preprocesamiento, la arquitectura y el entrenamiento.
  
- **Modelos:**  
  Solo se suben los modelos correspondientes a la 茅poca 100 de cada implementaci贸n.
  
- **Im谩genes de Ejemplo:**  
  En la carpeta `img_train_epochs` se guardan im谩genes generadas durante el entrenamiento (cada 5 茅pocas) para visualizar el progreso del entrenamiento la GAN.

---

## C贸mo Ejecutarlo

1. **Clonar el repositorio:**

   ```bash
   git clone https://github.com/warc0s/Fashion_MNIST_GAN
   cd Fashion_MNIST_GAN
   ```

2. **Instalar Dependencias:**

   - Para **TensorFlow**:
     ```bash
     pip install tensorflow matplotlib numpy
     ```
   - Para **PyTorch**:
     ```bash
     pip install torch torchvision matplotlib numpy
     ```
   
3. **Ejecutar las Celdas:**

   Ejecuta todas las celdas siguiendo el orden para reproducir el entrenamiento y generar los modelos y las im谩genes.

---

## Resultados

- **Calidad de las Im谩genes:**  
  A lo largo del entrenamiento, se pueden observar mejoras en la calidad de las im谩genes generadas. Las im谩genes guardadas en `img_train_epochs` muestran la evoluci贸n del generador cada 5 茅pocas.

- **Comparaci贸n entre Implementaciones:**  
  Aunque la versi贸n en TensorFlow tarda m谩s (usando CPU) en comparaci贸n con la versi贸n en PyTorch (usando GPU), ambos enfoques logran resultados casi id茅nticos en la generaci贸n de im谩genes.

---

## Licencia

Este proyecto se distribuye bajo la licencia MIT. Consulta el archivo [LICENSE](LICENSE) para m谩s detalles.
