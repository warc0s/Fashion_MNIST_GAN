{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Celda 1: Importar librerías, configurar semilla y parámetros iniciales"
      ],
      "metadata": {
        "id": "m8cdEPmiRBak"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEfwN1ESQtZq",
        "outputId": "d4d200ed-8544-4b65-869e-1d7db0261c87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Configuración de la semilla para reproducibilidad\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "random.seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "# Configuración del dispositivo (GPU si está disponible)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Usando dispositivo:\", device)\n",
        "\n",
        "# Parámetros globales\n",
        "LATENT_DIM = 100\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Celda 2: Cargar y preprocesar el dataset Fashion MNIST"
      ],
      "metadata": {
        "id": "PXhEDQKkRG_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la transformación: convertir a tensor y escalar a [0,1],\n",
        "# luego reescalamos a [-1, 1]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convierte a tensor y escala a [0,1]\n",
        "    transforms.Lambda(lambda x: (x - 0.5) * 2)  # Reescala a [-1,1]\n",
        "])\n",
        "\n",
        "# Descargar y cargar el dataset (solo la parte de entrenamiento, ignoramos las etiquetas)\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "# Creamos el DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "print(\"Dataset cargado y preprocesado. Tamaño del dataset:\", len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--CNPqwMRGdm",
        "outputId": "40592935-af67-4c72-b4f4-147e7ed431f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:03<00:00, 8.52MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 167kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.15MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
            "\n",
            "Dataset cargado y preprocesado. Tamaño del dataset: 60000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Celda 3: Definir el generador y el discriminador"
      ],
      "metadata": {
        "id": "ZZ4Qd8VlRIjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim=LATENT_DIM):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc = nn.Linear(latent_dim, 7 * 7 * 256, bias=False)\n",
        "        self.bn0 = nn.BatchNorm1d(7 * 7 * 256)\n",
        "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
        "\n",
        "        # Redimensionamos: salida esperada (batch, 256, 7, 7)\n",
        "        # Primera capa de deconvolución: 7x7 -> 7x7 (stride=1, padding=2 para kernel=5)\n",
        "        self.deconv1 = nn.ConvTranspose2d(256, 128, kernel_size=5, stride=1, padding=2, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "\n",
        "        # Segunda capa de deconvolución: 7x7 -> 14x14\n",
        "        # Usamos output_padding=1 para alcanzar la dimensión deseada\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # Capa final: 14x14 -> 28x28, salida 1 canal, activación tanh\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 1, kernel_size=5, stride=2, padding=2, output_padding=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch, LATENT_DIM)\n",
        "        x = self.fc(x)                     # (batch, 7*7*256)\n",
        "        x = self.bn0(x)\n",
        "        x = self.lrelu(x)\n",
        "        x = x.view(-1, 256, 7, 7)           # Reshape a (batch, 256, 7, 7)\n",
        "        x = self.deconv1(x)                # (batch, 128, 7, 7)\n",
        "        x = self.bn1(x)\n",
        "        x = self.lrelu(x)\n",
        "        x = self.deconv2(x)                # (batch, 64, 14, 14)\n",
        "        x = self.bn2(x)\n",
        "        x = self.lrelu(x)\n",
        "        x = self.deconv3(x)                # (batch, 1, 28, 28)\n",
        "        x = torch.tanh(x)                  # Asegura rango [-1, 1]\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # La entrada es de forma (batch, 1, 28, 28)\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2)  # 28 -> 14\n",
        "        self.lrelu = nn.LeakyReLU(0.2, inplace=True)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2)  # 14 -> 7\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(128 * 7 * 7, 1)  # Salida de un único valor\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)   # (batch, 64, 14, 14)\n",
        "        x = self.lrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.conv2(x)   # (batch, 128, 7, 7)\n",
        "        x = self.lrelu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc(x)\n",
        "        x = torch.sigmoid(x)  # Para obtener una salida en [0,1]\n",
        "        return x\n",
        "\n",
        "# Instanciar los modelos y moverlos al dispositivo\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Mostrar un resumen de la arquitectura (usando print)\n",
        "print(\"Resumen del Generador:\")\n",
        "print(generator)\n",
        "print(\"\\nResumen del Discriminador:\")\n",
        "print(discriminator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kSVEvwkRKL_",
        "outputId": "6b6401b2-e219-4ac1-fd0b-1f71af78915a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumen del Generador:\n",
            "Generator(\n",
            "  (fc): Linear(in_features=100, out_features=12544, bias=False)\n",
            "  (bn0): BatchNorm1d(12544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (deconv1): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (deconv3): ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
            ")\n",
            "\n",
            "Resumen del Discriminador:\n",
            "Discriminator(\n",
            "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "  (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc): Linear(in_features=6272, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Celda 4: Prueba de funcionamiento del generador y visualización"
      ],
      "metadata": {
        "id": "vlYbkx1CRLhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ponemos el generador en modo evaluación para evitar errores en BatchNorm con batch_size=1\n",
        "generator.eval()\n",
        "\n",
        "# Generar un vector latente aleatorio (ruido)\n",
        "noise = torch.randn(1, LATENT_DIM, device=device)\n",
        "with torch.no_grad():\n",
        "    generated_image = generator(noise)\n",
        "\n",
        "print(\"Dimensiones de la imagen generada:\", generated_image.shape)\n",
        "print(\"Rango de valores de la imagen generada: de\", generated_image.min().item(), \"a\", generated_image.max().item())\n",
        "\n",
        "# Mover la imagen a CPU para visualizarla y reescalar de [-1,1] a [0,1]\n",
        "generated_image_cpu = (generated_image.cpu().squeeze(0).squeeze(0) + 1) / 2\n",
        "\n",
        "plt.figure(dpi=80)\n",
        "plt.imshow(generated_image_cpu.numpy(), cmap='gray')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Imagen creada por el generador\")\n",
        "plt.show()\n",
        "\n",
        "# Si lo deseas, vuelve a poner el modelo en modo entrenamiento para continuar con el entrenamiento\n",
        "generator.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "eFrodv6MRNxa",
        "outputId": "9581fed4-37d2-49aa-c70a-641b10b2eecf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensiones de la imagen generada: torch.Size([1, 1, 28, 28])\n",
            "Rango de valores de la imagen generada: de -0.33828866481781006 a 0.30182838439941406\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 512x384 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (fc): Linear(in_features=100, out_features=12544, bias=False)\n",
              "  (bn0): BatchNorm1d(12544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (deconv1): ConvTranspose2d(256, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
              "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv2): ConvTranspose2d(128, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
              "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (deconv3): ConvTranspose2d(64, 1, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), output_padding=(1, 1), bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Celda 5: Prueba del discriminador con imagen generada\n"
      ],
      "metadata": {
        "id": "RW1hrbgNROJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ponemos ambos modelos en modo evaluación para evitar errores en BatchNorm con batch_size=1\n",
        "generator.eval()\n",
        "discriminator.eval()\n",
        "\n",
        "# Generar una imagen usando un vector latente aleatorio (ruido)\n",
        "noise = torch.randn(1, LATENT_DIM, device=device)\n",
        "with torch.no_grad():\n",
        "    generated_image = generator(noise)\n",
        "    decision = discriminator(generated_image)\n",
        "\n",
        "print(\"Decisión del discriminador (valor cercano a 0 = falsa, 1 = real):\", decision.cpu().numpy())\n",
        "\n",
        "# Si se requiere seguir entrenando, volver a poner los modelos en modo entrenamiento\n",
        "generator.train()\n",
        "discriminator.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWTeVfhzRPQt",
        "outputId": "49e5088e-058e-403a-e247-ed5f3c80abf4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decisión del discriminador (valor cercano a 0 = falsa, 1 = real): [[0.5035334]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (conv2): Conv2d(64, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc): Linear(in_features=6272, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Celda 6: Entrenamiento de la GAN\n"
      ],
      "metadata": {
        "id": "Q6NzgAY_RQbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la función de pérdida y los optimizadores\n",
        "criterion = nn.BCELoss()\n",
        "generator_optimizer = optim.Adam(generator.parameters(), lr=1e-4)\n",
        "discriminator_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "\n",
        "print(\"Inicio del entrenamiento de la GAN...\\n\")\n",
        "for epoch in range(EPOCHS):\n",
        "    total_disc_loss = 0.0\n",
        "    total_gen_loss = 0.0\n",
        "    batch_count = 0\n",
        "\n",
        "    for batch_idx, (real_images, _) in enumerate(train_loader):\n",
        "        batch_count += 1\n",
        "        current_batch_size = real_images.size(0)\n",
        "        real_images = real_images.to(device)\n",
        "\n",
        "        # Etiquetas reales y falsas\n",
        "        real_labels = torch.ones(current_batch_size, 1, device=device)\n",
        "        fake_labels = torch.zeros(current_batch_size, 1, device=device)\n",
        "\n",
        "        ####### Actualización del Discriminador #######\n",
        "        discriminator_optimizer.zero_grad()\n",
        "\n",
        "        # Evaluación en imágenes reales\n",
        "        real_output = discriminator(real_images)\n",
        "        loss_real = criterion(real_output, real_labels)\n",
        "\n",
        "        # Generar imágenes falsas\n",
        "        noise = torch.randn(current_batch_size, LATENT_DIM, device=device)\n",
        "        fake_images = generator(noise)\n",
        "        fake_output = discriminator(fake_images.detach())  # detach para no afectar al generador\n",
        "        loss_fake = criterion(fake_output, fake_labels)\n",
        "\n",
        "        # Pérdida total del discriminador y actualización\n",
        "        disc_loss = loss_real + loss_fake\n",
        "        disc_loss.backward()\n",
        "        discriminator_optimizer.step()\n",
        "\n",
        "        ####### Actualización del Generador #######\n",
        "        generator_optimizer.zero_grad()\n",
        "        # Generar imágenes y obtener la predicción del discriminador\n",
        "        noise = torch.randn(current_batch_size, LATENT_DIM, device=device)\n",
        "        fake_images = generator(noise)\n",
        "        # El generador quiere que el discriminador clasifique las imágenes como reales\n",
        "        fake_output = discriminator(fake_images)\n",
        "        gen_loss = criterion(fake_output, real_labels)\n",
        "        gen_loss.backward()\n",
        "        generator_optimizer.step()\n",
        "\n",
        "        total_disc_loss += disc_loss.item()\n",
        "        total_gen_loss += gen_loss.item()\n",
        "\n",
        "    avg_disc_loss = total_disc_loss / batch_count\n",
        "    avg_gen_loss = total_gen_loss / batch_count\n",
        "\n",
        "    print(f\"Época {epoch+1}/{EPOCHS} - Pérdida Discriminador: {avg_disc_loss:.4f}, Pérdida Generador: {avg_gen_loss:.4f}\")\n",
        "\n",
        "    # Cada 5 épocas se guardan los modelos y se genera una cuadrícula de imágenes de ejemplo\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        # Guardar los modelos\n",
        "        torch.save(generator.state_dict(), f\"fashion_mnist_generador_epoch{epoch+1}.pt\")\n",
        "        torch.save(discriminator.state_dict(), f\"fashion_mnist_discriminador_epoch{epoch+1}.pt\")\n",
        "\n",
        "        # Generar 9 imágenes de ejemplo\n",
        "        noise = torch.randn(9, LATENT_DIM, device=device)\n",
        "        with torch.no_grad():\n",
        "            generated_images = generator(noise)\n",
        "        # Reescalar de [-1, 1] a [0, 1]\n",
        "        generated_images = (generated_images + 1) / 2\n",
        "        generated_images = generated_images.cpu()\n",
        "\n",
        "        # Configurar la cuadrícula 3x3\n",
        "        fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
        "        for idx, ax in enumerate(axes.flat):\n",
        "            # Se extrae el canal único y se muestra en escala de grises\n",
        "            ax.imshow(generated_images[idx].squeeze(0).numpy(), cmap=\"gray\")\n",
        "            ax.axis(\"off\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"img_train_epoch{epoch+1}.png\")\n",
        "        plt.close(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SaWTl-6RRro",
        "outputId": "f22a70ef-e80c-415b-daa2-4cbf54c0ec83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inicio del entrenamiento de la GAN...\n",
            "\n",
            "Época 1/100 - Pérdida Discriminador: 0.6524, Pérdida Generador: 2.3616\n",
            "Época 2/100 - Pérdida Discriminador: 0.8156, Pérdida Generador: 1.7187\n",
            "Época 3/100 - Pérdida Discriminador: 0.7218, Pérdida Generador: 1.8771\n",
            "Época 4/100 - Pérdida Discriminador: 0.7674, Pérdida Generador: 1.8251\n",
            "Época 5/100 - Pérdida Discriminador: 0.8494, Pérdida Generador: 1.6320\n",
            "Época 6/100 - Pérdida Discriminador: 0.8888, Pérdida Generador: 1.5190\n",
            "Época 7/100 - Pérdida Discriminador: 0.9448, Pérdida Generador: 1.3984\n",
            "Época 8/100 - Pérdida Discriminador: 0.9891, Pérdida Generador: 1.3125\n",
            "Época 9/100 - Pérdida Discriminador: 1.0200, Pérdida Generador: 1.2808\n",
            "Época 10/100 - Pérdida Discriminador: 1.0391, Pérdida Generador: 1.2463\n",
            "Época 11/100 - Pérdida Discriminador: 1.0423, Pérdida Generador: 1.2284\n",
            "Época 12/100 - Pérdida Discriminador: 1.0826, Pérdida Generador: 1.1711\n",
            "Época 13/100 - Pérdida Discriminador: 1.0906, Pérdida Generador: 1.1795\n",
            "Época 14/100 - Pérdida Discriminador: 1.1054, Pérdida Generador: 1.1627\n",
            "Época 15/100 - Pérdida Discriminador: 1.1295, Pérdida Generador: 1.1122\n",
            "Época 16/100 - Pérdida Discriminador: 1.1512, Pérdida Generador: 1.0809\n",
            "Época 17/100 - Pérdida Discriminador: 1.1670, Pérdida Generador: 1.0678\n",
            "Época 18/100 - Pérdida Discriminador: 1.1777, Pérdida Generador: 1.0454\n",
            "Época 19/100 - Pérdida Discriminador: 1.1826, Pérdida Generador: 1.0419\n",
            "Época 20/100 - Pérdida Discriminador: 1.1887, Pérdida Generador: 1.0326\n",
            "Época 21/100 - Pérdida Discriminador: 1.1930, Pérdida Generador: 1.0173\n",
            "Época 22/100 - Pérdida Discriminador: 1.1988, Pérdida Generador: 1.0106\n",
            "Época 23/100 - Pérdida Discriminador: 1.2046, Pérdida Generador: 0.9992\n",
            "Época 24/100 - Pérdida Discriminador: 1.1608, Pérdida Generador: 1.1384\n",
            "Época 25/100 - Pérdida Discriminador: 1.2101, Pérdida Generador: 0.9973\n",
            "Época 26/100 - Pérdida Discriminador: 1.2170, Pérdida Generador: 0.9872\n",
            "Época 27/100 - Pérdida Discriminador: 1.2190, Pérdida Generador: 0.9800\n",
            "Época 28/100 - Pérdida Discriminador: 1.2188, Pérdida Generador: 0.9725\n",
            "Época 29/100 - Pérdida Discriminador: 1.2250, Pérdida Generador: 0.9720\n",
            "Época 30/100 - Pérdida Discriminador: 1.2228, Pérdida Generador: 0.9792\n",
            "Época 31/100 - Pérdida Discriminador: 1.2314, Pérdida Generador: 0.9580\n",
            "Época 32/100 - Pérdida Discriminador: 1.2254, Pérdida Generador: 0.9762\n",
            "Época 33/100 - Pérdida Discriminador: 1.2298, Pérdida Generador: 0.9536\n",
            "Época 34/100 - Pérdida Discriminador: 1.2339, Pérdida Generador: 0.9570\n",
            "Época 35/100 - Pérdida Discriminador: 1.2335, Pérdida Generador: 0.9568\n",
            "Época 36/100 - Pérdida Discriminador: 1.2365, Pérdida Generador: 0.9403\n",
            "Época 37/100 - Pérdida Discriminador: 1.2396, Pérdida Generador: 0.9420\n",
            "Época 38/100 - Pérdida Discriminador: 1.2426, Pérdida Generador: 0.9351\n",
            "Época 39/100 - Pérdida Discriminador: 1.1981, Pérdida Generador: 1.0492\n",
            "Época 40/100 - Pérdida Discriminador: 1.2436, Pérdida Generador: 0.9361\n",
            "Época 41/100 - Pérdida Discriminador: 1.2471, Pérdida Generador: 0.9325\n",
            "Época 42/100 - Pérdida Discriminador: 1.2467, Pérdida Generador: 0.9310\n",
            "Época 43/100 - Pérdida Discriminador: 1.2471, Pérdida Generador: 0.9388\n",
            "Época 44/100 - Pérdida Discriminador: 1.2505, Pérdida Generador: 0.9284\n",
            "Época 45/100 - Pérdida Discriminador: 1.2540, Pérdida Generador: 0.9186\n",
            "Época 46/100 - Pérdida Discriminador: 1.2469, Pérdida Generador: 0.9386\n",
            "Época 47/100 - Pérdida Discriminador: 1.2589, Pérdida Generador: 0.9148\n",
            "Época 48/100 - Pérdida Discriminador: 1.2609, Pérdida Generador: 0.9098\n",
            "Época 49/100 - Pérdida Discriminador: 1.2322, Pérdida Generador: 0.9771\n",
            "Época 50/100 - Pérdida Discriminador: 1.2605, Pérdida Generador: 0.9036\n",
            "Época 51/100 - Pérdida Discriminador: 1.2656, Pérdida Generador: 0.9040\n",
            "Época 52/100 - Pérdida Discriminador: 1.2631, Pérdida Generador: 0.9038\n",
            "Época 53/100 - Pérdida Discriminador: 1.2593, Pérdida Generador: 0.9207\n",
            "Época 54/100 - Pérdida Discriminador: 1.2636, Pérdida Generador: 0.9080\n",
            "Época 55/100 - Pérdida Discriminador: 1.2691, Pérdida Generador: 0.8935\n",
            "Época 56/100 - Pérdida Discriminador: 1.2665, Pérdida Generador: 0.8943\n",
            "Época 57/100 - Pérdida Discriminador: 1.2668, Pérdida Generador: 0.9051\n",
            "Época 58/100 - Pérdida Discriminador: 1.2694, Pérdida Generador: 0.8888\n",
            "Época 59/100 - Pérdida Discriminador: 1.2695, Pérdida Generador: 0.8951\n",
            "Época 60/100 - Pérdida Discriminador: 1.2600, Pérdida Generador: 0.9199\n",
            "Época 61/100 - Pérdida Discriminador: 1.2756, Pérdida Generador: 0.8846\n",
            "Época 62/100 - Pérdida Discriminador: 1.2147, Pérdida Generador: 1.0028\n",
            "Época 63/100 - Pérdida Discriminador: 1.2475, Pérdida Generador: 0.9626\n",
            "Época 64/100 - Pérdida Discriminador: 1.2735, Pérdida Generador: 0.8868\n",
            "Época 65/100 - Pérdida Discriminador: 1.2713, Pérdida Generador: 0.8899\n",
            "Época 66/100 - Pérdida Discriminador: 1.2742, Pérdida Generador: 0.8864\n",
            "Época 67/100 - Pérdida Discriminador: 1.2695, Pérdida Generador: 0.8935\n",
            "Época 68/100 - Pérdida Discriminador: 1.2740, Pérdida Generador: 0.8824\n",
            "Época 69/100 - Pérdida Discriminador: 1.2781, Pérdida Generador: 0.8792\n",
            "Época 70/100 - Pérdida Discriminador: 1.2686, Pérdida Generador: 0.8990\n",
            "Época 71/100 - Pérdida Discriminador: 1.2611, Pérdida Generador: 0.9314\n",
            "Época 72/100 - Pérdida Discriminador: 1.2760, Pérdida Generador: 0.8779\n",
            "Época 73/100 - Pérdida Discriminador: 1.2774, Pérdida Generador: 0.8707\n",
            "Época 74/100 - Pérdida Discriminador: 1.2779, Pérdida Generador: 0.8778\n",
            "Época 75/100 - Pérdida Discriminador: 1.2705, Pérdida Generador: 0.8980\n",
            "Época 76/100 - Pérdida Discriminador: 1.2834, Pérdida Generador: 0.8683\n",
            "Época 77/100 - Pérdida Discriminador: 1.2404, Pérdida Generador: 0.9813\n",
            "Época 78/100 - Pérdida Discriminador: 1.2794, Pérdida Generador: 0.8679\n",
            "Época 79/100 - Pérdida Discriminador: 1.2802, Pérdida Generador: 0.8684\n",
            "Época 80/100 - Pérdida Discriminador: 1.2847, Pérdida Generador: 0.8725\n",
            "Época 81/100 - Pérdida Discriminador: 1.2831, Pérdida Generador: 0.8704\n",
            "Época 82/100 - Pérdida Discriminador: 1.2819, Pérdida Generador: 0.8678\n",
            "Época 83/100 - Pérdida Discriminador: 1.2829, Pérdida Generador: 0.8663\n",
            "Época 84/100 - Pérdida Discriminador: 1.2062, Pérdida Generador: 1.0504\n",
            "Época 85/100 - Pérdida Discriminador: 1.2792, Pérdida Generador: 0.8672\n",
            "Época 86/100 - Pérdida Discriminador: 1.2814, Pérdida Generador: 0.8694\n",
            "Época 87/100 - Pérdida Discriminador: 1.2823, Pérdida Generador: 0.8657\n",
            "Época 88/100 - Pérdida Discriminador: 1.2827, Pérdida Generador: 0.8652\n",
            "Época 89/100 - Pérdida Discriminador: 1.2837, Pérdida Generador: 0.8637\n",
            "Época 90/100 - Pérdida Discriminador: 1.2689, Pérdida Generador: 0.9137\n",
            "Época 91/100 - Pérdida Discriminador: 1.2830, Pérdida Generador: 0.8741\n",
            "Época 92/100 - Pérdida Discriminador: 1.2871, Pérdida Generador: 0.8602\n",
            "Época 93/100 - Pérdida Discriminador: 1.2862, Pérdida Generador: 0.8632\n",
            "Época 94/100 - Pérdida Discriminador: 1.2876, Pérdida Generador: 0.8600\n",
            "Época 95/100 - Pérdida Discriminador: 1.2615, Pérdida Generador: 0.8984\n",
            "Época 96/100 - Pérdida Discriminador: 1.2590, Pérdida Generador: 0.9461\n",
            "Época 97/100 - Pérdida Discriminador: 1.2865, Pérdida Generador: 0.8602\n",
            "Época 98/100 - Pérdida Discriminador: 1.2851, Pérdida Generador: 0.8618\n",
            "Época 99/100 - Pérdida Discriminador: 1.2881, Pérdida Generador: 0.8605\n",
            "Época 100/100 - Pérdida Discriminador: 1.2911, Pérdida Generador: 0.8563\n"
          ]
        }
      ]
    }
  ]
}